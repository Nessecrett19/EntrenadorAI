<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Agente en A-Frame con Aprendizaje por Refuerzo</title>
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script> <!-- Cargar TensorFlow.js -->
  </head>
  <body>
    <a-scene>
      <!-- Obstáculos en el entorno -->
      <a-box position="2 1 -5" width="1" height="1" depth="1" color="red"></a-box>
      <a-box position="-2 1 -5" width="1" height="1" depth="1" color="red"></a-box>
      <a-box position="0 1 -3" width="1" height="1" depth="1" color="red"></a-box>

      <!-- Agente (esfera azul) -->
      <a-sphere id="agent" position="0 1 -3" radius="0.5" color="blue"></a-sphere>

      <!-- Cámara -->
      <a-camera position="0 1 0"></a-camera>
    </a-scene>

    <script>
      // Crear un modelo simple de red neuronal en TensorFlow.js
      const model = tf.sequential();
      model.add(tf.layers.dense({ units: 16, activation: 'relu', inputShape: [3] })); // 3 entradas: distancias de obstáculos
      model.add(tf.layers.dense({ units: 3, activation: 'softmax' })); // 3 salidas: izquierda, derecha, adelante

      model.compile({
        optimizer: tf.train.adam(0.01),
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy'],
      });

      // Función que calcula la distancia entre el agente y los obstáculos
      function getDistances() {
        const agent = document.getElementById('agent');
        const obstacles = document.querySelectorAll('a-box');
        
        let distances = [];
        obstacles.forEach((obstacle) => {
          const agentPos = agent.getAttribute('position');
          const obstaclePos = obstacle.getAttribute('position');
          const distance = Math.sqrt(
            Math.pow(agentPos.x - obstaclePos.x, 2) + 
            Math.pow(agentPos.z - obstaclePos.z, 2)
          );
          distances.push(distance);
        });
        return distances;
      }

      // Función de entrenamiento simple
      async function trainAgent() {
        let state = getDistances(); // Estado basado en distancias de obstáculos
        let action = await getAction(state); // Decisión del agente (izquierda, derecha, adelante)

        // Actualizar el entorno en función de la acción
        if (action === 0) { // Girar izquierda
          document.getElementById('agent').object3D.rotation.y += Math.PI / 10;
        } else if (action === 1) { // Girar derecha
          document.getElementById('agent').object3D.rotation.y -= Math.PI / 10;
        } else { // Mover adelante
          let position = document.getElementById('agent').getAttribute('position');
          position.z -= 0.1;
          document.getElementById('agent').setAttribute('position', position);
        }

        // Actualizar el modelo con las nuevas recompensas
        let reward = calculateReward(state); // Función que calcula la recompensa basada en el estado
        await trainModel(state, action, reward);
      }

      // Función para obtener la acción a partir del modelo
      async function getAction(state) {
        const input = tf.tensor2d([state]);
        const predictions = model.predict(input);
        const action = predictions.argMax(1).dataSync()[0];
        return action;
      }

      // Función que entrena el modelo con la recompensa
      async function trainModel(state, action, reward) {
        const input = tf.tensor2d([state]);
        const target = tf.tensor2d([[0, 0, 0]]);
        target.dataSync()[action] = reward;
        await model.fit(input, target, { epochs: 1 });
      }

      // Función para calcular la recompensa
      function calculateReward(state) {
        // Penaliza si el agente está demasiado cerca de un obstáculo
        return state.some(distance => distance < 1) ? -1 : 1;
      }

      // Iniciar el entrenamiento
      setInterval(trainAgent, 100);
    </script>
  </body>
</html>
