<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Agente en A-Frame con Aprendizaje por Refuerzo</title>
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script> <!-- Cargar TensorFlow.js -->
  </head>
  <body>
  <a-scene background="color: #a5faff">
      <!-- Agente -->
      <a-entity id="agent" position="0 0.160 -3" scale="0.01 0.01 0.01" gltf-model="tour_ia.glb"></a-entity>
    
      <!-- Habitación base -->
      <a-entity id="casa" position="0 0.169 -3" scale="9 9 9" gltf-model="habitacion1.glb"></a-entity>
    
      <!-- Muebles y objetos distribuidos dentro de la habitación -->
      <a-entity position="-0.63348 -15.64467 20.2487" scale="100 100 100" gltf-model="Librero.glb" visible="" rotation="0 180 0"></a-entity>
      <a-entity position="16.87996 -5.87886 -1.26722" scale="0.08 0.089 0.099" gltf-model="escritorio biblioteca.glb" visible="" rotation=""></a-entity>
      <a-entity position="5.89421 -16.03651 -1.17274" scale="10 10 10" gltf-model="silla biblioteca.glb" rotation="0 270 0"></a-entity>
      <a-entity position="-13.3353 -16.59778 19.44206" scale="10 10 10" gltf-model="planta 1.glb" visible=""></a-entity>
      <a-entity position="19.06531 -16.03257 18.13816" scale="2 2 2" gltf-model="planta 2.glb"></a-entity>
      <a-entity position="-19.76965 11.17943 11.6132" scale="1 11.02161 9.22213" gltf-model="cortina.glb"></a-entity>
      <a-entity position="-1.48626 -3.92519 3.85882" scale="4.04 3.54877 3.52717" gltf-model="Ventana.glb"></a-entity>
      <a-entity position="4 4 4" scale="1 1 1" gltf-model="libros.glb"></a-entity>
      
     
    
      <!-- Cámara -->
      <a-camera position="0 1 0"></a-camera>
  </a-scene>


    <script>
      // Definir los límites de la escena
      const SCENE_LIMIT_X = 5;  // Límite en el eje X
      const SCENE_LIMIT_Z = 5;  // Límite en el eje Z

      // Crear un modelo simple de red neuronal en TensorFlow.js
      const model = tf.sequential();
      model.add(tf.layers.dense({ units: 16, activation: 'relu', inputShape: [3] })); // 3 entradas: distancias de obstáculos
      model.add(tf.layers.dense({ units: 3, activation: 'softmax' })); // 3 salidas: izquierda, derecha, adelante

      model.compile({
        optimizer: tf.train.adam(0.01),
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy'],
      });

      // Función que calcula la distancia entre el agente y los obstáculos
      function getDistances() {
        const agent = document.getElementById('agent');
        const obstacles = document.querySelectorAll('a-box');
        
        let distances = [];
        obstacles.forEach((obstacle) => {
          const agentPos = agent.getAttribute('position');
          const obstaclePos = obstacle.getAttribute('position');
          const distance = Math.sqrt(
            Math.pow(agentPos.x - obstaclePos.x, 2) + 
            Math.pow(agentPos.z - obstaclePos.z, 2)
          );
          distances.push(distance);
        });
        return distances;
      }

      // Función de entrenamiento simple
      async function trainAgent() {
        let state = getDistances(); // Estado basado en distancias de obstáculos
        let action = await getAction(state); // Decisión del agente (izquierda, derecha, adelante)

        // Actualizar el entorno en función de la acción
        let position = document.getElementById('agent').getAttribute('position');
        
        if (action === 0) { // Girar izquierda
          document.getElementById('agent').object3D.rotation.y += Math.PI / 10;
        } else if (action === 1) { // Girar derecha
          document.getElementById('agent').object3D.rotation.y -= Math.PI / 10;
        } else { // Mover adelante
          position.z -= 0.1;
          
          // Limitar el movimiento en el eje Z (para que no se salga de la escena)
          if (Math.abs(position.z) > SCENE_LIMIT_Z) {
            position.z = Math.sign(position.z) * SCENE_LIMIT_Z;
          }

          position.x -= 0.1;
          
          // Limitar el movimiento en el eje X (para que no se salga de la escena)
          if (Math.abs(position.x) > SCENE_LIMIT_X) {
            position.x = Math.sign(position.x) * SCENE_LIMIT_X;
          }

          // Actualizar la posición
          document.getElementById('agent').setAttribute('position', position);
        }

        // Actualizar el modelo con las nuevas recompensas
        let reward = calculateReward(state); // Función que calcula la recompensa basada en el estado
        await trainModel(state, action, reward);
      }

      // Función para obtener la acción a partir del modelo
      async function getAction(state) {
        const input = tf.tensor2d([state]);
        const predictions = model.predict(input);
        const action = predictions.argMax(1).dataSync()[0];
        return action;
      }

      // Función que entrena el modelo con la recompensa
      async function trainModel(state, action, reward) {
        const input = tf.tensor2d([state]);
        const target = tf.tensor2d([[0, 0, 0]]);
        target.dataSync()[action] = reward;
        await model.fit(input, target, { epochs: 1 });
      }

      // Función para calcular la recompensa
      function calculateReward(state) {
        // Penaliza si el agente está demasiado cerca de un obstáculo
        return state.some(distance => distance < 1) ? -1 : 1;
      }

      // Iniciar el entrenamiento
      setInterval(trainAgent, 100);
    </script>
  </body>
</html>
